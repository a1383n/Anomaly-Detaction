{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Real-time Anomaly Detection using Optical Flow and Background Subtraction\n",
    "\n",
    "This notebook implements an anomaly detection system based on motion analysis. It learns a \"normal speed profile\" from training data and identifies deviations (anomalies) in test videos, such as vehicles on pedestrian paths or high-speed movements."
   ],
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T16:21:13.720647Z",
     "start_time": "2026-01-01T16:21:13.715755Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import os"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T16:21:13.782620Z",
     "start_time": "2026-01-01T16:21:13.772866Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Configuration Parameters\n",
    "DATASETS = [\"./data/UCSDped1\"]\n",
    "\n",
    "# Image dimensions for processing and display\n",
    "RESIZE_W, RESIZE_H = 238, 158\n",
    "DISPLAY_W, DISPLAY_H = 960, 540\n",
    "\n",
    "# Algorithm Sensitivity Tweaks\n",
    "CLAHE_CLIP = 1.5            # Contrast enhancement limit\n",
    "SENSITIVITY = 1.2           # Multiplier for the max speed model (lower = more sensitive)\n",
    "MIN_AREA = 200              # Minimum contour area to be flagged as an anomaly\n",
    "MOTION_DIFF_THRESH = 0.1    # Threshold for speed deviation\n",
    "SMOOTHING = 7               # Kernel size for Gaussian blur and morphology"
   ],
   "id": "818327affc9a9be9",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T16:21:13.832788Z",
     "start_time": "2026-01-01T16:21:13.828287Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dirs = []\n",
    "test_dirs = []\n",
    "for base in DATASETS:\n",
    "    train_dirs.extend(sorted(glob.glob(os.path.join(base, \"Train\", \"Train*\"))))\n",
    "    test_dirs.extend(sorted(glob.glob(os.path.join(base, \"Test\", \"Test*\"))))"
   ],
   "id": "ab67f73174750089",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Building the Normal Speed Model\n",
    "\n",
    "In this phase, we process the **Train** folders to calculate the maximum normal speed for every pixel.\n",
    "We use the **Farneback Optical Flow** algorithm to estimate motion between consecutive frames and maintain a `max_speed` map."
   ],
   "id": "b4ec2ac190146294"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T16:21:38.039022Z",
     "start_time": "2026-01-01T16:21:13.899462Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"[*] Building model from training folders...\")\n",
    "max_speed = np.zeros((RESIZE_H, RESIZE_W), dtype=np.float32)\n",
    "for folder in train_dirs:\n",
    "    frames = sorted(glob.glob(os.path.join(folder, \"*.tif*\")))\n",
    "    prev = None\n",
    "    for i in range(0, len(frames), 2):\n",
    "        img = cv2.imread(frames[i], cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            continue\n",
    "        g = cv2.resize(img, (RESIZE_W, RESIZE_H))\n",
    "        if prev is not None:\n",
    "            # Calculate Optical Flow between previous and current frame\n",
    "            flow = cv2.calcOpticalFlowFarneback(prev, g,\n",
    "                                                None,\n",
    "                                                pyr_scale=0.5, levels=3,\n",
    "                                                winsize=15, iterations=3,\n",
    "                                                poly_n=5, poly_sigma=1.2, flags=0)\n",
    "            mag, _ = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "\n",
    "            # Update the pixel-wise maximum speed model\n",
    "            max_speed = np.maximum(max_speed, mag)\n",
    "        prev = g\n",
    "# smooth model to remove outlier spikes\n",
    "max_speed = cv2.GaussianBlur(max_speed, (SMOOTHING, SMOOTHING), 0)\n",
    "# normalize to [0,1] for stability\n",
    "if max_speed.max() > 0:\n",
    "    max_speed /= max_speed.max()\n",
    "print(\"[*] Model built.\")"
   ],
   "id": "c8cb921fdce509e0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Building model from training folders...\n",
      "[*] Model built.\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T16:21:38.110858Z",
     "start_time": "2026-01-01T16:21:38.108828Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def enhance_contrast(gray):\n",
    "    \"\"\"Applies CLAHE to improve visibility in low-contrast grayscale frames.\"\"\"\n",
    "    clahe = cv2.createCLAHE(clipLimit=CLAHE_CLIP, tileGridSize=(8, 8))\n",
    "    return clahe.apply(gray)\n"
   ],
   "id": "902293a2c7e9e697",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T16:21:38.156039Z",
     "start_time": "2026-01-01T16:21:38.153879Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def visualize_heatmap(mag_norm):\n",
    "    \"\"\"Converts motion magnitude into a JET color-map for visualization.\"\"\"\n",
    "    heat = np.uint8(np.clip(mag_norm * 255.0, 0, 255))\n",
    "    heat = cv2.applyColorMap(heat, cv2.COLORMAP_JET)\n",
    "    return heat"
   ],
   "id": "10f089debeeb1ac8",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Anomaly Detection Logic\n",
    "\n",
    "The system identifies anomalies by combining two masks:\n",
    "1. **Background Subtraction (MOG2):** Detects any moving objects in the scene.\n",
    "2. **Speed Thresholding:** Compares the current motion magnitude with the learned `max_speed` model.\n",
    "If an object moves significantly faster than the learned threshold, it is enclosed in a **red bounding box**."
   ],
   "id": "6b42026616186fb5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T16:21:38.206381Z",
     "start_time": "2026-01-01T16:21:38.199609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_test_folder(folder, max_speed_model):\n",
    "    print(f\"[*] Processing test folder: {folder}\")\n",
    "    frames = sorted(glob.glob(os.path.join(folder, \"*.tif*\")))\n",
    "    if not frames:\n",
    "        return\n",
    "\n",
    "    backsub = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=16, detectShadows=True)\n",
    "    prev_gray = None\n",
    "\n",
    "    for idx, fpath in enumerate(frames):\n",
    "        bgr = cv2.imread(fpath)\n",
    "        if bgr is None:\n",
    "            continue\n",
    "\n",
    "        gray_full = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.resize(gray_full, (RESIZE_W, RESIZE_H))\n",
    "        gray = enhance_contrast(gray)\n",
    "\n",
    "        # Apply MOG2 Background Subtraction\n",
    "        fg_mask_full = backsub.apply(gray_full)\n",
    "        motion_mask = np.zeros_like(gray, dtype=np.uint8)\n",
    "        mag_norm = None\n",
    "\n",
    "        if prev_gray is not None:\n",
    "            # Calculate current motion magnitude\n",
    "            flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "            mag, _ = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "            mag_norm = mag / (mag.max() + 1e-8) if mag.max() > 0 else mag\n",
    "\n",
    "            # Logic: Highlight areas where current speed exceeds the learned model * sensitivity\n",
    "            diff = mag_norm - (max_speed_model * SENSITIVITY)\n",
    "            diff = np.clip(diff, 0, 1)\n",
    "            motion_mask = (diff > MOTION_DIFF_THRESH).astype(np.uint8) * 255\n",
    "\n",
    "        motion_full = cv2.resize(motion_mask, (gray_full.shape[1], gray_full.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        # Combine Background mask with Speed mask (Logical AND)\n",
    "        combined = cv2.bitwise_and(fg_mask_full, motion_full)\n",
    "        contours, _ = cv2.findContours(combined, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        display_right = cv2.resize(bgr.copy(), (DISPLAY_W, DISPLAY_H))\n",
    "        w_ratio = DISPLAY_W / gray_full.shape[1]\n",
    "        h_ratio = DISPLAY_H / gray_full.shape[0]\n",
    "\n",
    "        for cnt in contours:\n",
    "            if cv2.contourArea(cnt) > MIN_AREA:\n",
    "                x, y, w, h = cv2.boundingRect(cnt)\n",
    "                cv2.rectangle(display_right, (int(x*w_ratio), int(y*h_ratio)),\n",
    "                              (int((x+w)*w_ratio), int((y+h)*h_ratio)), (0, 0, 255), 2)\n",
    "\n",
    "        if mag_norm is not None:\n",
    "            heat = visualize_heatmap(cv2.resize(mag_norm, (DISPLAY_W, DISPLAY_H)))\n",
    "            display_right = cv2.addWeighted(display_right, 0.7, heat, 0.3, 0)\n",
    "\n",
    "        display_left = cv2.resize(bgr, (DISPLAY_W, DISPLAY_H))\n",
    "        side_by_side = np.hstack([display_left, display_right])\n",
    "\n",
    "        cv2.imshow(\"Original vs Analysis\", side_by_side)\n",
    "\n",
    "        prev_gray = gray\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()"
   ],
   "id": "2c69b32e4481fa1",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Results Visualization\n",
    "\n",
    "The output displays the **Original Frame** on the left and the **Analysis Overlay** on the right.\n",
    "The heatmap shows the intensity of motion, while red rectangles highlight the specific anomalous regions."
   ],
   "id": "3f811652a9bcbd6c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-01T16:23:23.227463Z",
     "start_time": "2026-01-01T16:21:38.264084Z"
    }
   },
   "cell_type": "code",
   "source": [
    "process_folders = [f for f in test_dirs if not f.endswith('_gt')]\n",
    "for f in process_folders:\n",
    "    process_test_folder(f, max_speed)"
   ],
   "id": "e9ba57922e7de39d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Processing test folder: ./data/UCSDped1/Test/Test001\n",
      "[*] Processing test folder: ./data/UCSDped1/Test/Test002\n",
      "[*] Processing test folder: ./data/UCSDped1/Test/Test003\n",
      "[*] Processing test folder: ./data/UCSDped1/Test/Test004\n",
      "[*] Processing test folder: ./data/UCSDped1/Test/Test005\n",
      "[*] Processing test folder: ./data/UCSDped1/Test/Test006\n",
      "[*] Processing test folder: ./data/UCSDped1/Test/Test007\n",
      "[*] Processing test folder: ./data/UCSDped1/Test/Test008\n",
      "[*] Processing test folder: ./data/UCSDped1/Test/Test009\n",
      "[*] Processing test folder: ./data/UCSDped1/Test/Test010\n",
      "[*] Processing test folder: ./data/UCSDped1/Test/Test011\n",
      "[*] Processing test folder: ./data/UCSDped1/Test/Test012\n",
      "[*] Processing test folder: ./data/UCSDped1/Test/Test013\n",
      "[*] Processing test folder: ./data/UCSDped1/Test/Test014\n",
      "[*] Processing test folder: ./data/UCSDped1/Test/Test015\n",
      "[*] Processing test folder: ./data/UCSDped1/Test/Test016\n",
      "[*] Processing test folder: ./data/UCSDped1/Test/Test017\n",
      "[*] Processing test folder: ./data/UCSDped1/Test/Test018\n",
      "[*] Processing test folder: ./data/UCSDped1/Test/Test019\n",
      "[*] Processing test folder: ./data/UCSDped1/Test/Test020\n",
      "[*] Processing test folder: ./data/UCSDped1/Test/Test021\n",
      "[*] Processing test folder: ./data/UCSDped1/Test/Test022\n",
      "[*] Processing test folder: ./data/UCSDped1/Test/Test023\n",
      "[*] Processing test folder: ./data/UCSDped1/Test/Test024\n",
      "[*] Processing test folder: ./data/UCSDped1/Test/Test025\n",
      "[*] Processing test folder: ./data/UCSDped1/Test/Test026\n",
      "[*] Processing test folder: ./data/UCSDped1/Test/Test027\n",
      "[*] Processing test folder: ./data/UCSDped1/Test/Test028\n",
      "[*] Processing test folder: ./data/UCSDped1/Test/Test029\n",
      "[*] Processing test folder: ./data/UCSDped1/Test/Test030\n",
      "[*] Processing test folder: ./data/UCSDped1/Test/Test031\n",
      "[*] Processing test folder: ./data/UCSDped1/Test/Test032\n",
      "[*] Processing test folder: ./data/UCSDped1/Test/Test033\n",
      "[*] Processing test folder: ./data/UCSDped1/Test/Test034\n",
      "[*] Processing test folder: ./data/UCSDped1/Test/Test035\n",
      "[*] Processing test folder: ./data/UCSDped1/Test/Test036\n"
     ]
    }
   ],
   "execution_count": 33
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
